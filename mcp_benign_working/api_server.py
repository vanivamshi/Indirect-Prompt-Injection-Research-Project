#!/usr/bin/env python3
"""
FastAPI Server for MCP Integration with Tool Chaining
This file provides the /api/chat endpoint with automatic URL processing and image handling.
"""

import re
import asyncio
import json
from typing import Dict, Any, List, Optional
from urllib.parse import urlparse, urljoin
import httpx
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

from mcp_client import MCPClient
from image_processor import (
    ImageProcessingResult, 
    extract_images_from_text, 
    process_image_with_google_search,
    process_gmail_with_image_and_url_chaining
)

# Initialize FastAPI app
app = FastAPI(
    title="MCP Integration API",
    description="API for MCP tool integration with automatic URL processing and image handling",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize MCP client
mcp_client = MCPClient()

# Pydantic models for request/response
class ChatRequest(BaseModel):
    message: str = Field(..., description="User message to process")
    max_urls: int = Field(default=3, description="Maximum number of URLs to process from emails")
    enable_tool_chaining: bool = Field(default=True, description="Enable automatic tool chaining")
    process_images: bool = Field(default=True, description="Enable image processing from emails")
    enable_summary: bool = True   # flag to control LLM summarization

class ChatResponse(BaseModel):
    success: bool
    message: str
    tool_results: List[Dict[str, Any]]
    processed_urls: List[Dict[str, Any]]
    processed_images: List[Dict[str, Any]]
    error: Optional[str] = None

class URLProcessingResult(BaseModel):
    url: str
    domain: str
    content_type: str
    content: Dict[str, Any]
    processing_time: float
    is_safe: bool

# ----------------------------
# Sanitizer for email bodies
# ----------------------------
def sanitize_email_body(body: str, max_chars: int = 1000) -> str:
    """Sanitize email text before sending to LLM."""
    if not body:
        return ""

    # Remove HTML tags
    clean = re.sub(r"<[^>]+>", " ", body)

    # Decode HTML entities
    clean = html.unescape(clean)

    # Redact common sensitive patterns
    clean = re.sub(r"(password\s*[:=]\s*\S+)", "[REDACTED PASSWORD]", clean, flags=re.I)
    clean = re.sub(r"(api[_-]?key\s*[:=]\s*\S+)", "[REDACTED API KEY]", clean, flags=re.I)
    clean = re.sub(r"([A-Za-z0-9+/=]{20,})", "[REDACTED TOKEN]", clean)

    # Collapse whitespace
    clean = re.sub(r"\s+", " ", clean).strip()

    # Truncate long bodies
    return clean[:max_chars]
   
# Helper functions to eliminate code duplication
async def process_urls_and_images_from_content(
    mcp_client, 
    content_data: List[Dict[str, Any]], 
    max_urls: int, 
    process_images: bool
) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """Process URLs and images from content data and return results"""
    url_results, image_results = await process_gmail_with_image_and_url_chaining(
        mcp_client,
        content_data, 
        max_urls,
        process_images
    )
    return url_results, image_results

def add_url_processing_results_to_tool_results(tool_results: List[Dict[str, Any]], url_results: List[Dict[str, Any]]):
    """Add URL processing results to tool results"""
    for url_result in url_results:
        tool_results.append({
            "tool": f"url_processing.{url_result.content_type}",
            "result": {
                "url": url_result.url,
                "domain": url_result.domain,
                "content": url_result.content,
                "processing_time": url_result.processing_time
            },
            "success": url_result.is_safe
        })

def add_image_processing_results_to_tool_results(tool_results: List[Dict[str, Any]], image_results: List[Dict[str, Any]]):
    """Add image processing results to tool results"""
    for image_result in image_results:
        tool_results.append({
            "tool": f"image_processing.{image_result.image_url.split('.')[-1] if '.' in image_result.image_url else 'unknown'}",
            "result": {
                "image_url": image_result.image_url,
                "source_email": image_result.source_email,
                "google_search_results": image_result.google_search_results,
                "web_content": image_result.web_content,
                "processing_time": image_result.processing_time
            },
            "success": image_result.is_safe
        })

# Safe domain whitelist
SAFE_DOMAINS = {
    "wikipedia.org",
    "en.wikipedia.org",
    "wikimedia.org",
    "github.com",
    "stackoverflow.com",
    "python.org",
    "docs.python.org",
    "developer.mozilla.org",
    "w3schools.com",
    "geeksforgeeks.org",
    "tutorialspoint.com",
    "realpython.com",
    "pythonprogramming.net",
    "learnpython.org",
    "pythonforbeginners.com",
    "pythoncentral.io",
    "pythonbasics.org",
    "python-course.eu",
    "pythonprogramminglanguage.com",
    "pythonprogramming.net",
    "pythonforbeginners.com",
    "pythoncentral.io",
    "pythonbasics.org",
    "python-course.eu",
    "pythonprogramminglanguage.com"
}

# Blocked domains for security
BLOCKED_DOMAINS = {
    "malware.com",
    "phishing.com",
    "scam.com",
    "virus.com",
    "hack.com",
    "exploit.com",
    "crack.com",
    "warez.com",
    "torrent.com",
    "pirate.com"
}

def is_safe_url(url: str) -> bool:
    """Check if URL is safe to process"""
    try:
        parsed = urlparse(url)
        domain = parsed.netloc.lower()
        
        # Check if domain is blocked
        if domain in BLOCKED_DOMAINS:
            return False
            
        # Check if domain is in safe whitelist
        if domain in SAFE_DOMAINS:
            return True
            
        # Check if it's a Wikipedia domain
        if "wikipedia.org" in domain:
            return True
            
        # Check if it's a localhost or internal IP (block for security)
        if domain in ["localhost", "127.0.0.1", "0.0.0.0"]:
            return False
            
        # Check for suspicious patterns
        suspicious_patterns = [
            r'\.(exe|bat|cmd|com|scr|pif|vbs|js|jar|msi|dmg|app)$',
            r'\.(onion|bit|tor)$',
            r'[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}',
            r'(admin|login|wp-admin|phpmyadmin|cpanel|webmail)',
            r'(\.ru|\.cn|\.tk|\.ml|\.ga|\.cf|\.gq)$'
        ]
        
        for pattern in suspicious_patterns:
            if re.search(pattern, url, re.IGNORECASE):
                return False
                
        return True
        
    except Exception:
        return False

def extract_urls_from_text(text: str) -> List[str]:
    """Extract URLs from text using multiple methods for better coverage"""
    if not text:
        return []
    
    print(f"üîç Extracting URLs from text: {text[:100]}...")
    
    # Method 1: Simple but effective pattern for common URLs
    simple_pattern = r'https?://[^\s<>"\'()]+'
    urls = re.findall(simple_pattern, text)
    
    # Method 2: More specific pattern for complex URLs with special characters
    complex_pattern = r'https?://[^\s<>"]+?(?=\s|$|[,;.!?])'
    complex_urls = re.findall(complex_pattern, text)
    
    # Method 3: Look for URLs in common formats
    format_pattern = r'https?://[a-zA-Z0-9\-._~:/?#[\]@!$&\'()*+,;=%]+'
    format_urls = re.findall(format_pattern, text)
    
    # Combine all methods and remove duplicates
    all_urls = urls + complex_urls + format_urls
    unique_urls = list(dict.fromkeys(all_urls))
    
    print(f"üîç Raw URLs found: {unique_urls}")
    
    # Clean and validate URLs
    cleaned_urls = []
    for url in unique_urls:
        # Remove trailing punctuation and whitespace
        url = url.strip().rstrip('.,;:!?')
        # Remove trailing quotes
        url = url.rstrip('"\'')
        # Remove trailing parentheses (but be careful not to break valid URLs)
        if url.count('(') > url.count(')'):
            # Only remove trailing parentheses if they're not balanced
            url = url.rstrip(')')
        
        # Additional validation
        if url and len(url) > 10 and '://' in url:
            if is_safe_url(url):
                cleaned_urls.append(url)
                print(f"üîç Final extracted URL: {url}")
    
    print(f"üîç Total URLs found: {len(cleaned_urls)}")
    
    # Fallback method: If no URLs found, try manual search
    if not cleaned_urls:
        print("üîç No URLs found with regex, trying manual search...")
        # Look for common URL patterns manually
        if 'https://' in text or 'http://' in text:
            # Find the start of URLs
            for protocol in ['https://', 'http://']:
                if protocol in text:
                    start_idx = text.find(protocol)
                    # Find the end (next space, newline, or punctuation)
                    end_chars = [' ', '\n', '\t', ',', '.', '!', '?', ';', ':', '"', "'", ')', ']', '}']
                    end_idx = len(text)
                    for char in end_chars:
                        pos = text.find(char, start_idx)
                        if pos != -1 and pos < end_idx:
                            end_idx = pos
                    
                    manual_url = text[start_idx:end_idx].strip()
                    if manual_url and len(manual_url) > 10:
                        print(f"üîç Manual URL found: {manual_url}")
                        if is_safe_url(manual_url):
                            cleaned_urls.append(manual_url)
                            print(f"üîç Manual URL added: {manual_url}")
    
    return cleaned_urls

def sanitize_email_body(body: str, max_chars: int = 1000) -> str:
    """Sanitize email text before sending to LLM."""
    if not body:
        return ""

    # Remove HTML tags
    clean = re.sub(r"<[^>]+>", " ", body)

    # Decode HTML entities
    clean = html.unescape(clean)

    # Redact common sensitive patterns
    clean = re.sub(r"(password\s*[:=]\s*\S+)", "[REDACTED PASSWORD]", clean, flags=re.I)
    clean = re.sub(r"(api[_-]?key\s*[:=]\s*\S+)", "[REDACTED API KEY]", clean, flags=re.I)
    clean = re.sub(r"([A-Za-z0-9+/=]{20,})", "[REDACTED TOKEN]", clean)  # JWTs, access tokens

    # Collapse whitespace
    clean = re.sub(r"\s+", " ", clean).strip()

    # Truncate long bodies
    return clean[:max_chars]

@app.on_event("startup")
async def startup_event():
    """Initialize MCP client on startup"""
    try:
        await mcp_client.connect_to_servers()
        print("‚úÖ MCP client initialized successfully")
    except Exception as e:
        print(f"‚ö†Ô∏è MCP client initialization warning: {e}")

@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    try:
        await mcp_client.disconnect()
        print("‚úÖ MCP client disconnected")
    except Exception as e:
        print(f"‚ö†Ô∏è MCP client disconnect warning: {e}")

@app.post("/api/chat", response_model=ChatResponse)
"""
async def chat_endpoint(request: ChatRequest):
    #Main chat endpoint with automatic tool chaining and image processing
    try:
        tool_results = []
        processed_urls = []
        processed_images = []
        
        # Process the user message
        user_input = request.message.lower()
        
        # Check if this is a Gmail-related request
        if any(word in user_input for word in ["gmail", "email", "mail", "inbox", "emails", "messages"]):
            print(f"üìß Processing Gmail request: {request.message}")
            
            # Check for specific image processing requests
            is_image_request = any(word in user_input for word in ["image", "images", "photo", "photos", "qr", "qr code", "picture", "pictures"])
            
            # Call Gmail tool
            if "get_messages" in user_input or "check" in user_input or "read" in user_input or "1st" in user_input or "first" in user_input:
                gmail_result = await mcp_client.call_tool("gmail", "get_messages", {
                    "query": "",
                    "max_results": 5
                })
                tool_results.append({
                    "tool": "gmail.get_messages",
                    "result": gmail_result,
                    "success": True
                })
                
                # If tool chaining is enabled, automatically process URLs and images
                if request.enable_tool_chaining and gmail_result.get("messages"):
                    print(f"üîó Tool chaining enabled - processing URLs and images from {len(gmail_result['messages'])} messages")
                    
                    # First, fetch the full content of each message
                    messages_with_content = []
                    for msg in gmail_result["messages"]:
                        try:
                            message_content = await mcp_client.call_tool("gmail", "get_message_content", {
                                "message_id": msg["id"]
                            })
                            # Combine metadata with content
                            """
                            full_message = {
                                "id": msg["id"],
                                "subject": msg.get("subject", ""),
                                "from": msg.get("from", ""),
                                "snippet": msg.get("snippet", ""),
                                "body": message_content.get("body", "")
                            }
                            """
                            full_message = message_content  # already has id, subject, from, snippet, body
                            messages_with_content.append(full_message)
                        except Exception as e:
                            print(f"‚ö†Ô∏è Failed to fetch content for message {msg['id']}: {e}")
                            # Fall back to using snippet if available
                            messages_with_content.append({
                                "id": msg["id"],
                                "subject": msg.get("subject", ""),
                                "from": msg.get("from", ""),
                                "snippet": msg.get("snippet", ""),
                                "body": msg.get("snippet", "")  # Use snippet as fallback
                            })
                    
                    # Now process URLs and images from the full message content
                    url_results, image_results = await process_urls_and_images_from_content(
                        mcp_client,
                        messages_with_content, 
                        request.max_urls,
                        request.process_images
                    )
                    processed_urls = url_results
                    processed_images = image_results
                    
                    # Add URL processing results to tool results
                    add_url_processing_results_to_tool_results(tool_results, url_results)
                    
                    # Add Image processing results to tool results
                    add_image_processing_results_to_tool_results(tool_results, image_results)
            
            elif "get_message_content" in user_input or "read message" in user_input:
                # Extract message ID if provided
                message_id_match = re.search(r'[a-f0-9]{16,}', request.message)
                if message_id_match:
                    message_id = message_id_match.group(0)
                    gmail_result = await mcp_client.call_tool("gmail", "get_message_content", {
                        "message_id": message_id
                    })
                    tool_results.append({
                        "tool": "gmail.get_message_content",
                        "result": gmail_result,
                        "success": True
                    })
                    
                    # Process URLs and images from message content
                    if request.enable_tool_chaining and gmail_result.get("body"):
                        urls = extract_urls_from_text(gmail_result["body"])
                        images = extract_images_from_text(gmail_result["body"])
                        
                        if urls or images:
                            print(f"üîó Processing {len(urls)} URLs and {len(images)} images from message content")
                            url_results, image_results = await process_urls_and_images_from_content(
                                mcp_client,
                                [{"body": gmail_result["body"]}], 
                                request.max_urls,
                                request.process_images
                            )
                            processed_urls = url_results
                            processed_images = image_results
                            
                            # Add URL processing results to tool results
                            add_url_processing_results_to_tool_results(tool_results, url_results)
                            
                            # Add Image processing results to tool results
                            add_image_processing_results_to_tool_results(tool_results, image_results)
                else:
                    tool_results.append({
                        "tool": "gmail.get_message_content",
                        "result": {"error": "No message ID provided"},
                        "success": False
                    })
        
        # Handle direct URL processing requests
        elif "http" in request.message:
            urls = extract_urls_from_text(request.message)
            images = extract_images_from_text(request.message)
            
            if urls or images:
                print(f"üåê Processing {len(urls)} URLs and {len(images)} images from message")
                url_results, image_results = await process_urls_and_images_from_content(
                    mcp_client,
                    [{"body": request.message}], 
                    request.max_urls,
                    request.process_images
                )
                processed_urls = url_results
                processed_images = image_results
                
                # Add URL processing results to tool results
                add_url_processing_results_to_tool_results(tool_results, url_results)
                
                # Add Image processing results to tool results
                add_image_processing_results_to_tool_results(tool_results, image_results)
        
        # Handle other tool requests
        else:
            # Default to Google search if no specific tool detected
            search_result = await mcp_client.call_tool("google", "search", {
                "query": request.message
            })
            tool_results.append({
                "tool": "google.search",
                "result": search_result,
                "success": True
            })
        
        # Prepare response
        response_message = f"Processed your request successfully. "
        if processed_urls:
            response_message += f"Found and processed {len(processed_urls)} URLs. "
        if processed_images:
            response_message += f"Found and processed {len(processed_images)} images. "
        if tool_results:
            response_message += f"Executed {len(tool_results)} tools."
        
        return ChatResponse(
            success=True,
            message=response_message,
            tool_results=tool_results,
            processed_urls=[url_result.dict() for url_result in processed_urls],
            processed_images=[image_result.dict() for image_result in processed_images]
        )
        
    except Exception as e:
        print(f"‚ùå Error in chat endpoint: {e}")
        return ChatResponse(
            success=False,
            message="An error occurred while processing your request",
            tool_results=[],
            processed_urls=[],
            processed_images=[],
            error=str(e)
        )
"""
async def chat_endpoint(request: ChatRequest):
    """Main chat endpoint with automatic tool chaining and image/URL/safe summarization processing"""
    try:
        tool_results = []
        processed_urls = []
        processed_images = []

        # Process the user message
        user_input = request.message.lower()

        # ---------------- Gmail Handling ----------------
        if any(word in user_input for word in ["gmail", "email", "mail", "inbox", "emails", "messages"]):
            print(f"üìß Processing Gmail request: {request.message}")

            gmail_result = await mcp_client.call_tool("gmail", "get_messages", {
                "query": "",
                "max_results": 5
            })
            tool_results.append({
                "tool": "gmail.get_messages",
                "result": gmail_result,
                "success": True
            })

            if request.enable_tool_chaining and gmail_result.get("messages"):
                print(f"üîó Tool chaining enabled - processing {len(gmail_result['messages'])} messages")

                messages_with_content = []
                for msg in gmail_result["messages"]:
                    try:
                        message_content = await mcp_client.call_tool(
                            "gmail", "get_message_content", {"message_id": msg["id"]}
                        )
                        body = message_content.get("body", "")

                        # ‚úÖ Local URL/image extraction
                        urls = extract_urls_from_text(body)
                        images = extract_images_from_text(body)

                        # === NEWLY ADDED ===
                        # Optional safe summarization
                        if request.enable_summary:
                            safe_body = sanitize_email_body(body)
                            llm_prompt = f"Summarize this email safely:\n\n{safe_body}"
                            try:
                                summary = await mcp_client.call_tool("llm", "chat", {"message": llm_prompt})
                                message_content["summary"] = summary
                            except Exception as e:
                                message_content["summary"] = f"(Summarization failed: {e})"
                        # === END NEW ===

                        messages_with_content.append(message_content)

                    except Exception as e:
                        print(f"‚ö†Ô∏è Failed to fetch content for message {msg['id']}: {e}")
                        messages_with_content.append({
                            "id": msg["id"],
                            "snippet": msg.get("snippet", ""),
                            "body": msg.get("snippet", "")
                        })

                # Process Gmail URLs/images
                url_results, image_results = await process_gmail_with_image_and_url_chaining(
                    mcp_client,
                    messages_with_content,
                    request.max_urls,
                    request.process_images
                )
                processed_urls = url_results
                processed_images = image_results

                # Add URL processing results
                for url_result in url_results:
                    tool_results.append({
                        "tool": f"url_processing",
                        "result": url_result.dict(),
                        "success": url_result.is_safe
                    })

                # Add Image processing results
                for image_result in image_results:
                    tool_results.append({
                        "tool": f"image_processing",
                        "result": image_result.dict(),
                        "success": image_result.is_safe
                    })

        # ---------------- Direct URL Handling ----------------
        elif "http" in request.message:
            urls = extract_urls_from_text(request.message)
            images = extract_images_from_text(request.message)
            if urls or images:
                url_results, image_results = await process_gmail_with_image_and_url_chaining(
                    mcp_client,
                    [{"body": request.message}],
                    request.max_urls,
                    request.process_images
                )
                processed_urls = url_results
                processed_images = image_results

        # ---------------- Default Google Search ----------------
        else:
            search_result = await mcp_client.call_tool("google", "search", {"query": request.message})
            tool_results.append({
                "tool": "google.search",
                "result": search_result,
                "success": True
            })

        # ---------------- Response ----------------
        response_message = f"Processed your request successfully. "
        if processed_urls:
            response_message += f"Found and processed {len(processed_urls)} URLs. "
        if processed_images:
            response_message += f"Found and processed {len(processed_images)} images. "
        if tool_results:
            response_message += f"Executed {len(tool_results)} tools."

        return ChatResponse(
            success=True,
            message=response_message,
            tool_results=tool_results,
            processed_urls=[u.dict() for u in processed_urls],
            processed_images=[i.dict() for i in processed_images]
        )

    except Exception as e:
        print(f"‚ùå Error in chat endpoint: {e}")
        return ChatResponse(
            success=False,
            message="An error occurred while processing your request",
            tool_results=[],
            processed_urls=[],
            processed_images=[],
            error=str(e)
        )

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "mcp_client_connected": mcp_client.servers != {}}

@app.get("/")
async def root():
    """Root endpoint with API information"""
    return {
        "message": "MCP Integration API",
        "version": "1.0.0",
        "endpoints": {
            "POST /api/chat": "Main chat endpoint with tool chaining and image processing",
            "GET /health": "Health check",
            "GET /": "API information"
        },
        "features": [
            "Automatic URL extraction from Gmail messages",
            "Automatic image extraction from Gmail messages",
            "Safe URL processing with domain validation",
            "Image processing with Google search integration",
            "Tool chaining between Gmail, web access, and Google search tools",
            "Injection-safe URL and image handling",
            "QR code and image analysis capabilities"
        ],
        "example_prompts": [
            "read my 1st email and process image",
            "check emails for images and URLs",
            "process QR codes in my inbox",
            "read emails and visit websites"
        ]
    }

if __name__ == "__main__":
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
